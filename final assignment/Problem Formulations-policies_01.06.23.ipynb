{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure pandas is version 1.0 or higher\n",
    "# make sure networkx is verion 2.4 or higher\n",
    "print(pd.__version__)\n",
    "print(nx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ema_workbench import (\n",
    "    Model,\n",
    "    Policy,\n",
    "    ema_logging,\n",
    "    SequentialEvaluator,\n",
    "    MultiprocessingEvaluator,\n",
    ")\n",
    "from dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "from problem_formulation import get_model_for_problem_formulation, sum_over, sum_over_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "# choose problem formulation number, between 0-5\n",
    "# each problem formulation has its own list of outcomes\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enlisting uncertainties, their types (RealParameter/IntegerParameter/CategoricalParameter), lower boundary, and upper boundary\n",
    "import copy\n",
    "\n",
    "for unc in dike_model.uncertainties:\n",
    "    print(repr(unc))\n",
    "\n",
    "uncertainties = copy.deepcopy(dike_model.uncertainties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enlisting policy levers, their types (RealParameter/IntegerParameter), lower boundary, and upper boundary\n",
    "for policy in dike_model.levers:\n",
    "    print(repr(policy))\n",
    "\n",
    "levers = copy.deepcopy(dike_model.levers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enlisting outcomes\n",
    "for outcome in dike_model.outcomes:\n",
    "    print(repr(outcome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the model through EMA workbench\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(scenarios=50, policies=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# observing the simulation runs\n",
    "experiments, outcomes = results\n",
    "print(outcomes.keys())\n",
    "experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only works because we have scalar outcomes\n",
    "pd.DataFrame(outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_do_nothing_dict():\n",
    "    return {l.name: 0 for l in dike_model.levers}\n",
    "\n",
    "# General remarks:\n",
    "# 1. For now we apply all levers at timestamp 0, so at the beginning of the 200years of the simulation.\n",
    "# It seems the levers can be also implemented after 67 or 133 years.\n",
    "# 2. For now we don't specify \"EWS_DaysToThreat\" as this is a secondary concern for determining the \n",
    "# preferred/best policy. It may be worth checking different values only after we choose the best policy.\n",
    "# 3. For now we select policies only with ring 4 interest in mind. Since they should come up with a shared preferred\n",
    "# policy with ring 5, maybe those should be combined with a lever that benefits ring 5.\n",
    "policies = [\n",
    "    Policy(\n",
    "        \"policy 1\",\n",
    "        # Big RfR in most upstream location (based on the map in ring 1 (non-organic farming)) -\n",
    "        # our client would prefer this, as they don't care about non-organic farming and it should \n",
    "        # significantly decrease flooding of ring 4 (town Gorssel).\n",
    "        **dict(\n",
    "            get_do_nothing_dict(),\n",
    "            **{\"0_RfR 0\": 1}\n",
    "            # **{\"0_RfR 0\": 1, \"0_RfR 1\": 1, \"0_RfR 2\": 1, \"A.1_DikeIncrease 0\": 5} - \n",
    "            # this was original \"policy 1\" - since the course manual states: (for RfR \n",
    "            #\"Once activated, the project remains active.\", I think \"\"0_RfR 1\": 1, \"0_RfR 2\": 1\" \n",
    "            # are redundant - but we should evaluate this.\n",
    "        )\n",
    "    ),\n",
    "    Policy(\n",
    "        \"policy 2\",\n",
    "        # Second best alternative of RfR from ring 4 perspective. Some RfR made upstream, \n",
    "        # some downstream from them, but none on their area. We choose this to have some comparison for policy 1.\n",
    "        **dict(\n",
    "            get_do_nothing_dict(),\n",
    "            **{\"3_RfR 0\": 1}\n",
    "        )\n",
    "    ),\n",
    "    Policy(\n",
    "        \"policy 3\",\n",
    "        # Only hightening dikes in ring 4 by the middle height of 0.5m (5 decimeters).\n",
    "        **dict(\n",
    "            get_do_nothing_dict(),\n",
    "            **{\"A.4_DikeIncrease 0\": 5}\n",
    "        )\n",
    "    ),\n",
    "    Policy(\n",
    "        \"policy 4\",\n",
    "        # Only hightening dikes in ring 4 by maximum height of 1m for comparison with policy 3.\n",
    "        **dict(\n",
    "            get_do_nothing_dict(),\n",
    "            **{\"A.4_DikeIncrease 0\": 10}\n",
    "        )\n",
    "    ),\n",
    "    Policy(\n",
    "        \"policy 5\",\n",
    "        # policy 1 + policy 3 - trade-off between costs of projects and max safety. Note that making more RfR \n",
    "        # (outside of ring 4 though, as they don't want to give up land) \n",
    "        # and hightening the dikes in ring 4 by more than 0.5m would increase ring 4 safety even further, but\n",
    "        # is unrealistic with limiteed budget and stakeholders' interests.\n",
    "        **dict(\n",
    "            get_do_nothing_dict(),\n",
    "            **{\"0_RfR 0\": 1, \"A.4_DikeIncrease 0\": 5}\n",
    "        )\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the policies list to EMA workbench experiment runs\n",
    "n_scenarios = 100\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(n_scenarios, policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, outcomes = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only works because we have scalar outcomes\n",
    "pd.DataFrame(outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
